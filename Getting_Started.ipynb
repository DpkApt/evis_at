{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting Started.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZB16RvwSQYD"
      },
      "source": [
        "Copyright &copy; University of Strasbourg. All Rights Reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8OJJD-kSTcD"
      },
      "source": [
        "<div>\n",
        "<a href=\"https://cholectriplet2021.grand-challenge.org/\">\n",
        "<img src=\"https://raw.githubusercontent.com/DpkApt/evis_at/master/pictures/header.png\" align=\"left\"/>\n",
        "</a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8aMfE5S74v"
      },
      "source": [
        "## <h1><center>Getting Started</center></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceAz2udUTolO"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hLKusP2TpGJ"
      },
      "source": [
        "In this notebook, we provide sample code to help familiarize yourself with the challenge, the dataset and the metrics. These are minimal examples to help illustrate a simple deep learning pipeline applied on a small subset of the Action Triplet dataset, **CholecT50**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__r_4n-QYILx"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri7fJFiXYJWj"
      },
      "source": [
        "# Tensorflow contains functions needed to build and train neural networks\n",
        "# Import relevant libraries\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print(\"Libraries successfully imported!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcQdB8OZWjcb"
      },
      "source": [
        "# Data Loading and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvzcRoaNYds7"
      },
      "source": [
        "# Download and extract the dataset from an online repository \n",
        "\n",
        "DATA_URL = (\n",
        "    'https://seafile.unistra.fr/f/8c8a776b74ac4eac9274/?dl=1'\n",
        ")\n",
        "dataset_path = tf.keras.utils.get_file('CholecT50-sample.zip', DATA_URL, extract=True)\n",
        "  \n",
        "#Stores the dataset in the variable \"path\"\n",
        "dataset_path = dataset_path.strip('.zip')  \n",
        "\n",
        "data_path = os.path.join(dataset_path, 'data')\n",
        "triplet_path = os.path.join(dataset_path, 'triplet')\n",
        "dict_path = os.path.join(dataset_path, 'dict')\n",
        "video_names = os.listdir(data_path)                                   \n",
        "\n",
        "print(\"Dataset successfully extracted!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk2y7u2s7i5J"
      },
      "source": [
        "# Create dictionary mapping triplet ids to readable label\n",
        "with open(os.path.join(dict_path, 'triplet.txt'), 'r') as f:\n",
        "  triplet_info = f.readlines()\n",
        "  triplet_dict = {}\n",
        "  for l in triplet_info:\n",
        "    triplet_id, triplet_label = l.split(':')\n",
        "    triplet_dict[int(triplet_id)] = triplet_label.rstrip()\n",
        "\n",
        "print('Random triplet id and its human readable label\\n')\n",
        "random_triplet_id = np.random.choice(list(triplet_dict.keys()))\n",
        "print('Triplet id: ', random_triplet_id, '\\nReadable label: ', triplet_dict[random_triplet_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLDza6yst9-I"
      },
      "source": [
        "def generator(data_path, triplet_path, video_names, shuffle=False):\n",
        "  while True:\n",
        "    if shuffle:\n",
        "      video_names = np.random.shuffle(video_names)\n",
        "\n",
        "    for video_name in video_names:\n",
        "      with open(os.path.join(triplet_path, video_name + '.txt'), mode='r') as infile:\n",
        "          reader = csv.reader(infile)\n",
        "          for line in reader:\n",
        "            line = np.array(line, np.uint8)\n",
        "            frame_id, triplet_label = line[0], line[1:]\n",
        "            image_path = os.path.join(data_path, video_name, \"%06d.png\" %frame_id)\n",
        "            image = np.array(Image.open(image_path), np.float32) / 255.0\n",
        "            yield image, triplet_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0SZBNWSyf7g"
      },
      "source": [
        "gen = generator(data_path, triplet_path, video_names)\n",
        "for image, triplet_label in gen:\n",
        "  print('Visualizing image...\\n')\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "  print('\\nEncoding showing which of the 100 considered action triplets are represented in the image\\n')\n",
        "  print(triplet_label)\n",
        "  print('\\nReadable labels\\n')\n",
        "  for triplet in np.where(triplet_label)[0]:\n",
        "    print(triplet_dict[triplet])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBl9-4gOWof0"
      },
      "source": [
        "#  Building and running models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JbM-RYZEJf4"
      },
      "source": [
        "Defining a shallow neural network using tf.keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl65rM9IAmqi"
      },
      "source": [
        "# Defining the neural network architecture\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(\n",
        "    filters=16, kernel_size=3, strides=2, activation=\"relu\", input_shape=(480, 854, 3))\n",
        ")                 \n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides = 2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.Flatten())                                     \n",
        "model.add(tf.keras.layers.Dense(units=4096, activation=\"relu\"))                 \n",
        "model.add(tf.keras.layers.Dense(units=2048, activation=\"relu\"))            \n",
        "model.add(tf.keras.layers.Dense(units=100, activation=\"sigmoid\"))    \n",
        "\n",
        "print(\"Neural network architecture successfully defined!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ_Yp4e6A_Q-"
      },
      "source": [
        "model.build([1, 480, 854, 3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aZ4baDLDAYS"
      },
      "source": [
        "input_4d = np.expand_dims(image, axis=0)\n",
        "print('Performing a simple forward pass on our untrained network for a test image')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "print('\\nPrediction\\n')\n",
        "print(model.predict(input_4d)[0])\n",
        "print('\\nLabel\\n')\n",
        "print(triplet_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_4F2W7uWs5V"
      },
      "source": [
        "#  Metrics and evaluation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLK2JMF4ET2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}